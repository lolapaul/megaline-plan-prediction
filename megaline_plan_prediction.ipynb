{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto\n",
    "\n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "El objetivo es desarrollar un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud es 0.75. Usaremos el data set para comprobar la exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar base de datos para análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ",
    "# Importar dataset\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3214, 5)\n",
      "\n",
      "*****************************************************************\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "*****************************************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "*****************************************************************\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Explorar dataset\n",
    "print(df.shape)\n",
    "print()\n",
    "print(\"*****************************************************************\")\n",
    "print(df.head())\n",
    "print()\n",
    "print(\"*****************************************************************\")\n",
    "print(df.info())\n",
    "print()\n",
    "print(\"*****************************************************************\")\n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tipo de datos estan asignados corretamente. Vemos que el dataset incluye las llamadas, minutos, mensajes y megas usados en cada plan. Se tiene una columna que identifica si el plan es ultra con un 1, y si dice 0, se refiere a que es el plan smart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentar datos\n",
    "\n",
    "Vamos a segmentar los datos en un conjunto de entrenamiento, uno de validación y otro de prueba. Separaré la base de datos en una proporción de 60%, 20% y 20% respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar el dataset en entrenamiento, validación y prueba\n",
    "df_train, df_temp = train_test_split(df, test_size=0.4, random_state=12345)\n",
    "df_valid, df_test = train_test_split(df_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Declarar variables para las caraceteristicas y para la caracteristica objetivo\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigar exactitud de varios modelos\n",
    "\n",
    "Probaré tres modelos para analizar mi informacón: Decision Tree Classifier, Random Forest Classifer y Logist Regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "El mejor max_depth = 3 con una exactitud de: 0.7853810264385692\n",
      "\n",
      "RandomForestClassifier\n",
      "El mejor n_estimators = 12 con una exactitud de: 0.7869362363919129\n",
      "\n",
      "LogisticRegression\n",
      "Exactitud del set de entrenamiento: 0.7505186721991701\n",
      "Exactitud del set de validación: 0.7589424572317263\n"
     ]
    }
   ],
   "source": [
    "# Modelo DecisionTreeClassifier\n",
    "best_score_dtc = 0\n",
    "best_depth = 0\n",
    "for depth in range(1,29):\n",
    "    model_dtc = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_dtc.fit(features_train,target_train)\n",
    "    predictions_valid = model_dtc.predict(features_valid)\n",
    "    score = accuracy_score(target_valid,predictions_valid)\n",
    "    if score > best_score_dtc:\n",
    "        best_score_dtc = score\n",
    "        best_depth = depth\n",
    "print(\"DecisionTreeClassifier\")\n",
    "print(\"El mejor max_depth =\", best_depth, \"con una exactitud de:\", best_score_dtc)\n",
    "print()\n",
    "\n",
    "# Modelo RandomForestClassifier\n",
    "best_score_rfc = 0\n",
    "best_est = 0\n",
    "for est in range(1, 15): # selecciona el rango del hiperparámetro\n",
    "    model_rfc = RandomForestClassifier(random_state=12345, n_estimators= est) # configura el número de árboles\n",
    "    model_rfc.fit(features_train, target_train) # entrena el modelo en el conjunto de entrenamiento\n",
    "    score = model_rfc.score(features_valid, target_valid) # calcula la puntuación de accuracy en el conjunto de validación\n",
    "    if score > best_score_rfc:\n",
    "        best_score_rfc = score # guarda la mejor puntuación de accuracy en el conjunto de validación\n",
    "        best_est = est # guarda el número de estimadores que corresponden a la mejor puntuación de exactitud\n",
    "print(\"RandomForestClassifier\")\n",
    "print(\"El mejor n_estimators =\", best_est, \"con una exactitud de:\", best_score_rfc)\n",
    "print()\n",
    "\n",
    "# Modelo LogisticRegression\n",
    "model_lr = LogisticRegression(random_state=12345, solver='liblinear') # inicializa el constructor de regresión logística con los parámetros random_state=54321 y solver='liblinear'\n",
    "model_lr.fit(features_train,target_train) # entrena el modelo en el conjunto de entrenamiento\n",
    "score_train = model_lr.score(features_train,target_train) # calcula la puntuación de accuracy en el conjunto de entrenamiento\n",
    "score_valid = model_lr.score(features_valid,target_valid) # calcula la puntuación de accuracy en el conjunto de validación\n",
    "print(\"LogisticRegression\")\n",
    "print(\"Exactitud del set de entrenamiento:\", score_train)\n",
    "print(\"Exactitud del set de validación:\", score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los modelos Decision Tree Classifer y Random Forest Classifier modifique los parametros max_depth y n_estimators respectivamente, y e itere sobre un rango para encontrar cual era el mejor hiperparametro. El tiempo de respuesta fue realmente rápido en ambos casos. \n",
    "\n",
    "En el caso del modelo Logistic Regression utilice el parametro liblinear, que era el mejor para la cantidad de datos que tenemos por analizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escoger el mejor modelo usando el conjunto de prueba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El mejor modelo es  RandomForestClassifier\n",
      "El rendimiento del modelo RandomForestClassifier en el set de prueba es : 0.7869362363919129\n"
     ]
    }
   ],
   "source": [
    "# Escoger el mejor modelos y evaluarlo con el set de prueba\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "if max(best_score_dtc, best_score_rfc, score_valid) == best_score_dtc:\n",
    "    best_model = DecisionTreeClassifier(random_state=12345, max_depth=best_depth)\n",
    "    best_model_name = \"DecisionTreeClassifier\"\n",
    "elif max(best_score_dtc, best_score_rfc, score_valid) == best_score_rfc:\n",
    "    best_model = RandomForestClassifier(random_state=12345, n_estimators=best_est)\n",
    "    best_model_name = \"RandomForestClassifier\"\n",
    "else:\n",
    "    best_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "    best_model_name = \"LogisticRegression\"\n",
    "\n",
    "best_model.fit(features_train, target_train)\n",
    "predictions_test = best_model.predict(features_test)\n",
    "score_test = accuracy_score(target_test, predictions_test)\n",
    "\n",
    "\n",
    "print(\"\\nEl mejor modelo es\", best_model_name)\n",
    "print(\"La exactitud del modelo\", best_model_name, \"en el set de prueba es :\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, utilice el set de prueba y lo probé en los tres modelos para saber cual era el que tenia mayor exactitud, y el resultado fue que Random Forest Classifier era el mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
